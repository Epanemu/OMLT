{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Optimal adversaries for dense MNIST model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building and training the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import requisite packages\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show how to load the dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set training and test batch sizes\n",
    "train_kwargs = {'batch_size': 64}\n",
    "test_kwargs = {'batch_size': 1000}\n",
    "\n",
    "#Build DataLoaders for training and test sets\n",
    "dataset1 = datasets.MNIST('../data', train=True, download=True, transform=transforms.ToTensor())\n",
    "dataset2 = datasets.MNIST('../data', train=False, transform=transforms.ToTensor())\n",
    "train_loader = torch.utils.data.DataLoader(dataset1,**train_kwargs, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset2, **test_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 50\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1  = nn.Conv2d(1, 8, (4,4), (2,2), 0)\n",
    "        self.conv2  = nn.Conv2d(8, 8, (4,4), (2,2), 0)\n",
    "        self.hidden1 = nn.Linear(5 * 5 * 8, hidden_size)\n",
    "        self.output  = nn.Linear(hidden_size, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x1 = self.conv1(x)\n",
    "        self.x2 = self.relu(self.x1)\n",
    "        self.x3 = self.conv2(self.x2)\n",
    "        self.x4 = self.relu(self.x3)\n",
    "        self.x5 = self.hidden1(self.x4.view((-1,5*5*8)))\n",
    "        self.x6 = self.relu(self.x5)\n",
    "        self.x7 = self.output(self.x6)\n",
    "        x = self.softmax(self.x7)      \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define train and test functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    criterion = nn.NLLLoss()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 200  == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            \n",
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0; correct = 0\n",
    "    criterion = nn.NLLLoss(reduction='sum')\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).item()  \n",
    "            pred = output.argmax(dim=1, keepdim=True) \n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset), 100. * correct / len(test_loader.dataset)))            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model on dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.294026\n",
      "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 0.259291\n",
      "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 0.041207\n",
      "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 0.110864\n",
      "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 0.190586\n",
      "\n",
      "Test set: Average loss: 0.0924, Accuracy: 9700/10000 (97%)\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.014803\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.078992\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.054852\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.166482\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.031017\n",
      "\n",
      "Test set: Average loss: 0.0719, Accuracy: 9757/10000 (98%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.040141\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.024642\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.009056\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.120740\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.013258\n",
      "\n",
      "Test set: Average loss: 0.0569, Accuracy: 9809/10000 (98%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.053137\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.013043\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.010585\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.043555\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.047870\n",
      "\n",
      "Test set: Average loss: 0.0571, Accuracy: 9800/10000 (98%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.108120\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.023335\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.088022\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.125782\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.042551\n",
      "\n",
      "Test set: Average loss: 0.0492, Accuracy: 9845/10000 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Net()\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=1)\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=0.7)\n",
    "\n",
    "for epoch in range(5):\n",
    "    train(model, train_loader, optimizer, epoch)\n",
    "    test(model, test_loader)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the MIP formulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to export to ONNX, the PyTorch ONNX exporter needs to write to a file so we generate a temporary file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.onnx\n",
    "import tempfile\n",
    "from omlt.io.onnx import write_onnx_model_with_bounds, load_onnx_neural_network_with_bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also define bounds on variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_index = 0\n",
    "image = dataset2[problem_index][0].detach().numpy()\n",
    "label = dataset2[problem_index][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon_infty = 5e-2\n",
    "lb = np.maximum(0, image - epsilon_infty)\n",
    "ub = np.minimum(1, image + epsilon_infty)\n",
    "\n",
    "input_bounds = {}\n",
    "for i in range(28):\n",
    "    for j in range(28):\n",
    "        input_bounds[(0,i,j)] = (float(lb[0][i,j]), float(ub[0][i,j])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch needs to trace the model execution to export it, so we defined a dummy input tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataset2[problem_index][0].view(-1,1,28,28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can write the ONNX model and load it back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NoSoftmaxNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1  = nn.Conv2d(1, 8, (4,4), (2,2), 0)\n",
    "        self.conv2  = nn.Conv2d(8, 8, (4,4), (2,2), 0)\n",
    "        self.hidden1 = nn.Linear(5 * 5 * 8, hidden_size)\n",
    "        self.output  = nn.Linear(hidden_size, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x1 = self.conv1(x)\n",
    "        self.x2 = self.relu(self.x1)\n",
    "        self.x3 = self.conv2(self.x2)\n",
    "        self.x4 = self.relu(self.x3)\n",
    "        self.x5 = self.hidden1(self.x4.view((-1,5*5*8)))\n",
    "        self.x6 = self.relu(self.x5)\n",
    "        self.x7 = self.output(self.x6)\n",
    "        x = self.softmax(self.x7)      \n",
    "        return x\n",
    "    \n",
    "model2 = NoSoftmaxNet()\n",
    "model2.load_state_dict(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tempfile.NamedTemporaryFile(suffix='.onnx', delete=False) as f:\n",
    "    torch.onnx.export(\n",
    "        model2,\n",
    "        x,\n",
    "        f,\n",
    "        input_names=['input'],\n",
    "        output_names=['output'],\n",
    "        dynamic_axes={\n",
    "            'input': {0: 'batch_size'},\n",
    "            'output': {0: 'batch_size'}\n",
    "        }\n",
    "    )\n",
    "    write_onnx_model_with_bounds(f.name, None, input_bounds)\n",
    "    # load back\n",
    "    network_definition = load_onnx_neural_network_with_bounds(f.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Pyomo model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyomo.environ as pyo\n",
    "from omlt import OmltBlock\n",
    "from omlt.neuralnet import NeuralNetworkFormulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tInputLayer(input_size=[1, 28, 28], output_size=[1, 28, 28])\tlinear\n",
      "1\tConvLayer(input_size=[1, 28, 28], output_size=[8, 13, 13], strides=[2, 2], kernel_shape=(4, 4))\trelu\n",
      "2\tConvLayer(input_size=[8, 13, 13], output_size=[8, 5, 5], strides=[2, 2], kernel_shape=(4, 4))\trelu\n",
      "3\tDenseLayer(input_size=[1, 200], output_size=[1, 50])\trelu\n",
      "4\tDenseLayer(input_size=[1, 50], output_size=[1, 10])\tlogsoftmax\n"
     ]
    }
   ],
   "source": [
    "for layer_id, layer in enumerate(network_definition.layers):\n",
    "    print(f\"{layer_id}\\t{layer}\\t{layer.activation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OMLT doesn't include a formulation for sigmoid, so define it here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'_BlockData' object has no attribute 'constraints'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-3704991e68af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOmltBlock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_formulation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformulation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/omlt-0.3.1.post1.dev99+gb0ccafd-py3.8.egg/omlt/block.py\u001b[0m in \u001b[0;36mbuild_formulation\u001b[0;34m(self, formulation)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;31m# tell the formulation object to construct the necessary models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__formulation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_formulation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/omlt-0.3.1.post1.dev99+gb0ccafd-py3.8.egg/omlt/neuralnet/nn_formulation.py\u001b[0m in \u001b[0;36m_build_formulation\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     76\u001b[0m                                      self.__scaled_input_bounds)\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         _build_neural_network_formulation(\n\u001b[0m\u001b[1;32m     79\u001b[0m             \u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mnetwork_structure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__network_definition\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/omlt-0.3.1.post1.dev99+gb0ccafd-py3.8.egg/omlt/neuralnet/nn_formulation.py\u001b[0m in \u001b[0;36m_build_neural_network_formulation\u001b[0;34m(block, network_structure, layer_constraints, activation_constraints)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mactivation_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactivation_constraints\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0mconstraint_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_block\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0mactivation_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_block\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/omlt-0.3.1.post1.dev99+gb0ccafd-py3.8.egg/omlt/neuralnet/layers/full_space.py\u001b[0m in \u001b[0;36mfull_space_conv_layer\u001b[0;34m(net_block, net, layer_block, layer)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mlayer_block\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzhat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moutput_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mub\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mlayer_block\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstraints\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_block\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzhat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moutput_index\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mexpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pyomo/core/base/block.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, val)\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0;31m# Since the base classes don't support getattr, we can just\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;31m# throw the \"normal\" AttributeError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m         raise AttributeError(\"'%s' object has no attribute '%s'\"\n\u001b[0m\u001b[1;32m    522\u001b[0m                              % (self.__class__.__name__, val))\n\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: '_BlockData' object has no attribute 'constraints'"
     ]
    }
   ],
   "source": [
    "formulation = NeuralNetworkFormulation(network_definition)\n",
    "    #activation_constraints={'relu': relu_activation}\n",
    "#)\n",
    "\n",
    "m = pyo.ConcreteModel()\n",
    "\n",
    "m.nn = OmltBlock()\n",
    "m.nn.build_formulation(formulation) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.obj = pyo.Objective(expr=(-(m.nn.outputs[label+1]-m.nn.outputs[label])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academic license - for non-commercial use only - expires 2023-01-12\n",
      "Using license file /Users/calvintsay/gurobi.lic\n",
      "Read LP format model from file /var/folders/pc/7mzx4b956_lb2l8_ryngwydc0000gn/T/tmp7ns5p94m.pyomo.lp\n",
      "Reading time = 0.04 seconds\n",
      "x2693: 2109 rows, 2693 columns, 46307 nonzeros\n",
      "Gurobi Optimizer version 9.1.1 build v9.1.1rc0 (mac64)\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "Optimize a model with 2109 rows, 2693 columns and 46307 nonzeros\n",
      "Model fingerprint: 0xb20823a5\n",
      "Variable types: 2593 continuous, 100 integer (100 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [2e-06, 1e+01]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [4e-03, 8e+01]\n",
      "  RHS range        [3e-04, 1e+01]\n",
      "Presolve removed 1831 rows and 1696 columns\n",
      "Presolve time: 0.09s\n",
      "Presolved: 278 rows, 997 columns, 30454 nonzeros\n",
      "Variable types: 932 continuous, 65 integer (65 binary)\n",
      "\n",
      "Root relaxation: objective -8.661667e+00, 140 iterations, 0.01 seconds\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0   -8.66167    0   33          -   -8.66167      -     -    0s\n",
      "     0     0   -3.88263    0   37          -   -3.88263      -     -    0s\n",
      "     0     0   -3.26626    0   38          -   -3.26626      -     -    0s\n",
      "     0     0   -3.26622    0   38          -   -3.26622      -     -    0s\n",
      "     0     0   -2.64909    0   37          -   -2.64909      -     -    0s\n",
      "     0     0   -2.51544    0   37          -   -2.51544      -     -    0s\n",
      "     0     0   -2.51464    0   37          -   -2.51464      -     -    0s\n",
      "H    0     0                       7.0848057   -2.51464   135%     -    0s\n",
      "     0     0   -2.02632    0   34    7.08481   -2.02632   129%     -    0s\n",
      "H    0     0                       6.5133920   -2.02632   131%     -    0s\n",
      "     0     0   -1.89253    0   34    6.51339   -1.89253   129%     -    0s\n",
      "     0     0   -1.30312    0   34    6.51339   -1.30312   120%     -    0s\n",
      "     0     0   -0.76776    0   34    6.51339   -0.76776   112%     -    0s\n",
      "     0     0   -0.33808    0   34    6.51339   -0.33808   105%     -    0s\n",
      "H    0     0                       3.9967749   -0.33808   108%     -    0s\n",
      "     0     0    0.18624    0   34    3.99677    0.18624  95.3%     -    0s\n",
      "     0     0    3.28829    0   32    3.99677    3.28829  17.7%     -    0s\n",
      "     0     2    3.28829    0   32    3.99677    3.28829  17.7%     -    1s\n",
      "\n",
      "Cutting planes:\n",
      "  Gomory: 9\n",
      "  MIR: 33\n",
      "  Flow cover: 5\n",
      "  RLT: 40\n",
      "  Relax-and-lift: 1\n",
      "\n",
      "Explored 157 nodes (3461 simplex iterations) in 1.16 seconds\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 3: 3.99677 6.51339 7.08481 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 3.996774871164e+00, best bound 3.996774871164e+00, gap 0.0000%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Problem': [{'Name': 'x2693', 'Lower bound': 3.9967748711641224, 'Upper bound': 3.996774871164125, 'Number of objectives': 1, 'Number of constraints': 2109, 'Number of variables': 2693, 'Number of binary variables': 100, 'Number of integer variables': 100, 'Number of continuous variables': 2593, 'Number of nonzeros': 46307, 'Sense': 'minimize'}], 'Solver': [{'Status': 'ok', 'Return code': '0', 'Message': 'Model was solved to optimality (subject to tolerances), and an optimal solution is available.', 'Termination condition': 'optimal', 'Termination message': 'Model was solved to optimality (subject to tolerances), and an optimal solution is available.', 'Wall time': '1.1556038856506348', 'Error rc': 0, 'Time': 1.2740771770477295}], 'Solution': [OrderedDict([('number of solutions', 0), ('number of solutions displayed', 0)])]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyo.SolverFactory('gurobi').solve(m, tee=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b8f31a8284ce774e9ad8d309790c576c984c0620550967f9ef361ac8e66f487d"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
