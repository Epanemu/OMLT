{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Optimal adversaries for dense MNIST model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building and training the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import requisite packages\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show how to load the dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set training and test batch sizes\n",
    "train_kwargs = {'batch_size': 64}\n",
    "test_kwargs = {'batch_size': 1000}\n",
    "\n",
    "#Build DataLoaders for training and test sets\n",
    "dataset1 = datasets.MNIST('../data', train=True, download=True, transform=transforms.ToTensor())\n",
    "dataset2 = datasets.MNIST('../data', train=False, transform=transforms.ToTensor())\n",
    "train_loader = torch.utils.data.DataLoader(dataset1,**train_kwargs, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset2, **test_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 50\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1  = nn.Conv2d(1, 4, (4,4), (2,2), 0)\n",
    "        self.conv2  = nn.Conv2d(4, 4, (4,4), (2,2), 0)\n",
    "        self.hidden1 = nn.Linear(5*5*4, hidden_size)\n",
    "        self.output  = nn.Linear(hidden_size, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x1 = self.conv1(x)\n",
    "        self.x2 = self.relu(self.x1)\n",
    "        self.x3 = self.conv2(self.x2)\n",
    "        self.x4 = self.relu(self.x3)\n",
    "        self.x5 = self.hidden1(self.x4.view((-1,5*5*4)))\n",
    "        self.x6 = self.relu(self.x5)\n",
    "        self.x7 = self.output(self.x6)\n",
    "        x = self.softmax(self.x7)      \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define train and test functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    criterion = nn.NLLLoss()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 200  == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            \n",
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0; correct = 0\n",
    "    criterion = nn.NLLLoss(reduction='sum')\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).item()  \n",
    "            pred = output.argmax(dim=1, keepdim=True) \n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset), 100. * correct / len(test_loader.dataset)))            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model on dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.304583\n",
      "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 0.183861\n",
      "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 0.196545\n",
      "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 0.157393\n",
      "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 0.179011\n",
      "\n",
      "Test set: Average loss: 0.1301, Accuracy: 9591/10000 (96%)\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.141424\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.088089\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.046966\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.041039\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.152068\n",
      "\n",
      "Test set: Average loss: 0.1000, Accuracy: 9667/10000 (97%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.146375\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.054521\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.181353\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.036283\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.111440\n",
      "\n",
      "Test set: Average loss: 0.0796, Accuracy: 9741/10000 (97%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.107770\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.045193\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.051702\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.113249\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.170987\n",
      "\n",
      "Test set: Average loss: 0.0697, Accuracy: 9763/10000 (98%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.030719\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.046459\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.015963\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.098893\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.201976\n",
      "\n",
      "Test set: Average loss: 0.0674, Accuracy: 9783/10000 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Net()\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=1)\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=0.7)\n",
    "\n",
    "for epoch in range(5):\n",
    "    train(model, train_loader, optimizer, epoch)\n",
    "    test(model, test_loader)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the MIP formulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to export to ONNX, the PyTorch ONNX exporter needs to write to a file so we generate a temporary file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.onnx\n",
    "import tempfile\n",
    "from omlt.io.onnx import write_onnx_model_with_bounds, load_onnx_neural_network_with_bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also define bounds on variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_index = 0\n",
    "image = dataset2[problem_index][0].detach().numpy()\n",
    "label = dataset2[problem_index][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon_infty = 1e-3\n",
    "lb = np.maximum(0, image - epsilon_infty)\n",
    "ub = np.minimum(1, image + epsilon_infty)\n",
    "\n",
    "input_bounds = {}\n",
    "for i in range(28):\n",
    "    for j in range(28):\n",
    "        input_bounds[(0,i,j)] = (float(lb[0][i,j]), float(ub[0][i,j])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch needs to trace the model execution to export it, so we defined a dummy input tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataset2[problem_index][0].view(-1,1,28,28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can write the ONNX model and load it back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NoSoftmaxNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1  = nn.Conv2d(1, 4, (4,4), (2,2), 0)\n",
    "        self.conv2  = nn.Conv2d(4, 4, (4,4), (2,2), 0)\n",
    "        self.hidden1 = nn.Linear(5 * 5 * 4, hidden_size)\n",
    "        self.output  = nn.Linear(hidden_size, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x1 = self.conv1(x)\n",
    "        self.x2 = self.relu(self.x1)\n",
    "        self.x3 = self.conv2(self.x2)\n",
    "        self.x4 = self.relu(self.x3)\n",
    "        self.x5 = self.hidden1(self.x4.view((-1,5*5*4)))\n",
    "        self.x6 = self.relu(self.x5)\n",
    "        x = self.output(self.x6)    \n",
    "        return x\n",
    "    \n",
    "model2 = NoSoftmaxNet()\n",
    "model2.load_state_dict(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tempfile.NamedTemporaryFile(suffix='.onnx', delete=False) as f:\n",
    "    torch.onnx.export(\n",
    "        model2,\n",
    "        x,\n",
    "        f,\n",
    "        input_names=['input'],\n",
    "        output_names=['output'],\n",
    "        dynamic_axes={\n",
    "            'input': {0: 'batch_size'},\n",
    "            'output': {0: 'batch_size'}\n",
    "        }\n",
    "    )\n",
    "    write_onnx_model_with_bounds(f.name, None, input_bounds)\n",
    "    # load back\n",
    "    network_definition = load_onnx_neural_network_with_bounds(f.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Pyomo model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyomo.environ as pyo\n",
    "from omlt import OmltBlock\n",
    "from omlt.neuralnet import NeuralNetworkFormulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tInputLayer(input_size=[1, 28, 28], output_size=[1, 28, 28])\tlinear\n",
      "1\tConvLayer(input_size=[1, 28, 28], output_size=[8, 13, 13], strides=[2, 2], kernel_shape=(4, 4))\trelu\n",
      "2\tConvLayer(input_size=[8, 13, 13], output_size=[8, 5, 5], strides=[2, 2], kernel_shape=(4, 4))\trelu\n",
      "3\tDenseLayer(input_size=[1, 200], output_size=[1, 50])\trelu\n",
      "4\tDenseLayer(input_size=[1, 50], output_size=[1, 10])\tlinear\n"
     ]
    }
   ],
   "source": [
    "for layer_id, layer in enumerate(network_definition.layers):\n",
    "    print(f\"{layer_id}\\t{layer}\\t{layer.activation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OMLT doesn't include a formulation for sigmoid, so define it here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "formulation = NeuralNetworkFormulation(network_definition)\n",
    "    #activation_constraints={'relu': relu_activation}\n",
    "#)\n",
    "\n",
    "m = pyo.ConcreteModel()\n",
    "\n",
    "m.nn = OmltBlock()\n",
    "m.nn.build_formulation(formulation) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Implicitly replacing the Component attribute obj (type=<class\n",
      "    'pyomo.core.base.objective.ScalarObjective'>) on block unknown with a new\n",
      "    Component (type=<class 'pyomo.core.base.objective.ScalarObjective'>). This\n",
      "    is usually indicative of a modelling error. To avoid this warning, use\n",
      "    block.del_component() and block.add_component().\n"
     ]
    }
   ],
   "source": [
    "m.obj = pyo.Objective(expr=(-(m.nn.outputs[0,label+1]-m.nn.outputs[0,label])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academic license - for non-commercial use only - expires 2023-01-12\n",
      "Using license file /Users/calvintsay/gurobi.lic\n",
      "Read LP format model from file /var/folders/pc/7mzx4b956_lb2l8_ryngwydc0000gn/T/tmp3g_n1c9z.pyomo.lp\n",
      "Reading time = 0.04 seconds\n",
      "x4871: 5739 rows, 4871 columns, 33357 nonzeros\n",
      "Changed value of parameter mipgap to 0.01\n",
      "   Prev: 0.0001  Min: 0.0  Max: inf  Default: 0.0001\n",
      "Gurobi Optimizer version 9.1.1 build v9.1.1rc0 (mac64)\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "Optimize a model with 5739 rows, 4871 columns and 33357 nonzeros\n",
      "Model fingerprint: 0x4cbec30b\n",
      "Variable types: 4045 continuous, 826 integer (826 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [5e-05, 2e+01]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [5e-04, 1e+02]\n",
      "  RHS range        [5e-04, 2e+01]\n",
      "Presolve removed 3765 rows and 2576 columns\n",
      "Presolve time: 0.03s\n",
      "Presolved: 1974 rows, 2295 columns, 15952 nonzeros\n",
      "Variable types: 1844 continuous, 451 integer (451 binary)\n",
      "\n",
      "Root relaxation: objective 1.081139e+01, 750 iterations, 0.01 seconds\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0   10.81139    0  193          -   10.81139      -     -    0s\n",
      "     0     0   10.83151    0  186          -   10.83151      -     -    0s\n",
      "     0     0   10.83726    0  186          -   10.83726      -     -    0s\n",
      "     0     0   10.83813    0  187          -   10.83813      -     -    0s\n",
      "H    0     0                      10.8619190   10.83813  0.22%     -    0s\n",
      "H    0     0                      10.8569052   10.83813  0.17%     -    0s\n",
      "\n",
      "Cutting planes:\n",
      "  MIR: 20\n",
      "  Flow cover: 12\n",
      "  RLT: 33\n",
      "\n",
      "Explored 1 nodes (1129 simplex iterations) in 0.39 seconds\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 2: 10.8569 10.8619 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-02)\n",
      "Best objective 1.085690518475e+01, best bound 1.083812948842e+01, gap 0.1729%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Problem': [{'Name': 'x4871', 'Lower bound': 10.838129488422629, 'Upper bound': 10.856905184748015, 'Number of objectives': 1, 'Number of constraints': 5739, 'Number of variables': 4871, 'Number of binary variables': 826, 'Number of integer variables': 826, 'Number of continuous variables': 4045, 'Number of nonzeros': 33357, 'Sense': 'minimize'}], 'Solver': [{'Status': 'ok', 'Return code': '0', 'Message': 'Model was solved to optimality (subject to tolerances), and an optimal solution is available.', 'Termination condition': 'optimal', 'Termination message': 'Model was solved to optimality (subject to tolerances), and an optimal solution is available.', 'Wall time': '0.388592004776001', 'Error rc': 0, 'Time': 0.509326696395874}], 'Solution': [OrderedDict([('number of solutions', 0), ('number of solutions displayed', 0)])]}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solver = pyo.SolverFactory('gurobi')\n",
    "solver.options['mipgap'] = 0.01\n",
    "solver.solve(m, tee=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b8f31a8284ce774e9ad8d309790c576c984c0620550967f9ef361ac8e66f487d"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
