{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1be2240",
   "metadata": {},
   "source": [
    "# Bayesian Optimization with Trees in OMLT\n",
    "\n",
    "This notebook introduces the gradient-boosted trees (GBT) functionality of `OMLT` and how such models can be incorporated in Bayesian optimization loops. For a more comprehensive framework using GBT models for Bayesian optimization please check out another project of our group: [ENTMOOT](https://github.com/cog-imperial/entmoot)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e86cf82",
   "metadata": {},
   "source": [
    "## List of Python Imports\n",
    "We start by importing a list of dependencies to implement the example. `OMLT` is compatible with all tree ensemble training libraries that support ONNX outputs. In this tutorial we use the `lightgbm` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69b8fd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import tempfile\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import pyomo.environ as pe\n",
    "from onnxmltools.convert.lightgbm.convert import convert\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "from omlt.block import OmltBlock\n",
    "from omlt.gbt import BigMFormulation, GradientBoostedTreeModel\n",
    "\n",
    "from helpers import generate_gbt_data\n",
    "\n",
    "random.seed(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb93c95",
   "metadata": {},
   "source": [
    "## Define Dataset\n",
    "We first define a simple dataset by sampling 100 random points from the 10D Rastrigin function. Every input feature of the Rastrigin function is bounded by `(-5.12, 5.12)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45f9fa84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(X):\n",
    "    # Rastrigin benchmark function\n",
    "    x = np.asarray_chkfinite(X)\n",
    "    n = len(x)\n",
    "    res = 10*n + sum( x**2 - 10 * np.cos( 2 * np.pi * x ))\n",
    "    return res\n",
    "\n",
    "f_bnds = [(-5.12,5.12) for _ in range(10)]\n",
    "\n",
    "# generate dataset\n",
    "data = {'X': [], 'y': []}\n",
    "\n",
    "for _ in range(100):\n",
    "    sample =[random.uniform(*bnd) for bnd in f_bnds]\n",
    "    \n",
    "    data['X'].append(sample)\n",
    "    data['y'].append(f(sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe952fbe",
   "metadata": {},
   "source": [
    "## Train the Tree Ensemble\n",
    "Next we define our training function to train the tree ensemble based on the data we generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f43157cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_tree(data):\n",
    "    FIXED_PARAMS = {'objective': 'regression',\n",
    "                    'metric': 'rmse',\n",
    "                    'boosting': 'gbdt',\n",
    "                    'num_trees': 20,\n",
    "                    'max_depth': 3,\n",
    "                    'min_data_in_leaf': 2,\n",
    "                    'min_data_per_group': 2,\n",
    "                    'random_state': 100,\n",
    "                    'verbose': -1}\n",
    "\n",
    "    train_data = lgb.Dataset(data['X'], \n",
    "                             label=data['y'],\n",
    "                             params={'verbose': -1})\n",
    "\n",
    "    model = lgb.train(FIXED_PARAMS, \n",
    "                      train_data,\n",
    "                      verbose_eval=False)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f2127b",
   "metadata": {},
   "source": [
    "## Handling Trees with ONNX\n",
    "ONNX needs to know the number of features and their type. Currently, ONNX doesn't support categorical features so we can only train models with continous features in `lightgbm`. To handle categorical features we recommend to perform a one-hot encoding transformation first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c88bfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_onnx_model(lgb_model):\n",
    "    # export onnx model\n",
    "    float_tensor_type = FloatTensorType([None, lgb_model.num_feature()])\n",
    "    initial_type = [('float_input', float_tensor_type)]\n",
    "    onnx_model = convert(lgb_model, \n",
    "                         initial_types=initial_type, \n",
    "                         target_opset=8)\n",
    "    return onnx_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f3eff0",
   "metadata": {},
   "source": [
    "You can write the ONNX model to a file so that it can be inspected using a tool like [Netron](https://netron.app/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d71706df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Onnx model written to /run/user/1000/tmpcy88u6te.onnx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fra/Hacks/imperial/OptML/venv/lib/python3.8/site-packages/lightgbm/engine.py:148: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    }
   ],
   "source": [
    "# build lightgbm model and export from onnx\n",
    "lgb_model = train_tree(data)\n",
    "onnx_model = get_onnx_model(lgb_model)\n",
    "\n",
    "with tempfile.NamedTemporaryFile(suffix='.onnx', delete=False) as f:\n",
    "    f.write(onnx_model.SerializeToString())\n",
    "    print(f'Onnx model written to {f.name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368cbfdb",
   "metadata": {},
   "source": [
    "## Build the Pyomo Model\n",
    "We build the `Pyomo` model by first defining the input bounds and input domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a03e619e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define problem specifications\n",
    "input_bounds = f_bnds\n",
    "input_domain = [pe.Reals for _ in range(len(input_bounds))]\n",
    "\n",
    "def get_opt_model_core(input_domain, input_bounds):\n",
    "    # init optimization model\n",
    "    opt_model = pe.ConcreteModel()\n",
    "\n",
    "    return opt_model\n",
    "\n",
    "opt_model = get_opt_model_core(input_domain, input_bounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2bf141",
   "metadata": {},
   "source": [
    "We can print the model to check if everything worked correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1092bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Declarations: \n"
     ]
    }
   ],
   "source": [
    "opt_model.pprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42448a4",
   "metadata": {},
   "source": [
    "We import the general `OMLT` block and the `GradientBoostedTreeModel` module. `OMLT` uses `BigMFormulation` to encode the tree ensembles. This optimization model formulation was adapted from Misic 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "067c6910",
   "metadata": {},
   "outputs": [],
   "source": [
    "from omlt.block import OmltBlock\n",
    "from omlt.gbt import BigMFormulation, GradientBoostedTreeModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6175e4f1",
   "metadata": {},
   "source": [
    "In include the tree model as a `Pyomo` block we import a few objects from `OMLT` and add everything to our optimization model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a386025",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_tree_model(opt_model, onnx_model, input_bounds):\n",
    "    # init omlt block and gbt model based on the onnx format\n",
    "    opt_model.gbt = OmltBlock()\n",
    "    gbt_model = GradientBoostedTreeModel(onnx_model, \n",
    "                                         input_bounds=input_bounds)\n",
    "    \n",
    "    # omlt uses a big-m formulation to encode the tree models\n",
    "    formulation = BigMFormulation(gbt_model)\n",
    "    opt_model.gbt.build_formulation(formulation)\n",
    "    opt_model.obj = pe.Objective(expr=opt_model.gbt.outputs[0])\n",
    "    \n",
    "add_tree_model(opt_model, onnx_model, input_bounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67394ac2",
   "metadata": {},
   "source": [
    "Solve the problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f239d5ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Implicitly replacing the Component attribute obj (type=<class\n",
      "    'pyomo.core.base.objective.ScalarObjective'>) on block unknown with a new\n",
      "    Component (type=<class 'pyomo.core.base.objective.ScalarObjective'>). This\n",
      "    is usually indicative of a modelling error. To avoid this warning, use\n",
      "    block.del_component() and block.add_component().\n",
      "Welcome to the CBC MILP Solver \n",
      "Version: 2.9.10 \n",
      "Build Date: Feb 23 2019 \n",
      "\n",
      "command line - /home/fra/.nix-profile/bin/cbc -printingOptions all -import /run/user/1000/tmpbybnnyab.pyomo.lp -stat=1 -solve -solu /run/user/1000/tmpbybnnyab.pyomo.soln (default strategy 1)\n",
      "Option for printingOptions changed from normal to all\n",
      "Presolve 387 (-74) rows, 222 (-2) columns and 1055 (-293) elements\n",
      "Statistics for presolved model\n",
      "Original problem has 65 integers (65 of which binary)\n",
      "Presolved problem has 65 integers (65 of which binary)\n",
      "==== 75 zero objective 148 different\n",
      "==== absolute objective values 148 different\n",
      "==== for integers 65 zero objective 1 different\n",
      "65 variables have objective of 0\n",
      "==== for integers absolute objective values 1 different\n",
      "65 variables have objective of 0\n",
      "===== end objective counts\n",
      "\n",
      "\n",
      "Problem has 387 rows, 222 columns (147 with objective) and 1055 elements\n",
      "Column breakdown:\n",
      "147 of type 0.0->inf, 0 of type 0.0->up, 0 of type lo->inf, \n",
      "10 of type lo->up, 0 of type free, 0 of type fixed, \n",
      "0 of type -inf->0.0, 0 of type -inf->up, 65 of type 0.0->1.0 \n",
      "Row breakdown:\n",
      "0 of type E 0.0, 20 of type E 1.0, 0 of type E -1.0, \n",
      "0 of type E other, 0 of type G 0.0, 0 of type G 1.0, \n",
      "0 of type G other, 186 of type L 0.0, 55 of type L 1.0, \n",
      "126 of type L other, 0 of type Range 0.0->1.0, 0 of type Range other, \n",
      "0 of type Free \n",
      "Continuous objective value is 148.288 - 0.00 seconds\n",
      "Cgl0003I 0 fixed, 0 tightened bounds, 129 strengthened rows, 0 substitutions\n",
      "Cgl0003I 0 fixed, 0 tightened bounds, 64 strengthened rows, 0 substitutions\n",
      "Cgl0003I 0 fixed, 0 tightened bounds, 12 strengthened rows, 0 substitutions\n",
      "Cgl0003I 0 fixed, 0 tightened bounds, 4 strengthened rows, 0 substitutions\n",
      "Cgl0004I processed model has 387 rows, 222 columns (65 integer (65 of which binary)) and 1264 elements\n",
      "Cbc0038I Initial state - 0 integers unsatisfied sum - 8.88178e-15\n",
      "Cbc0038I Solution found of 148.288\n",
      "Cbc0038I Relaxing continuous gives 148.288\n",
      "Cbc0038I Before mini branch and bound, 65 integers at bound fixed and 153 continuous\n",
      "Cbc0038I Mini branch and bound did not improve solution (0.01 seconds)\n",
      "Cbc0038I After 0.01 seconds - Feasibility pump exiting with objective of 148.288 - took 0.00 seconds\n",
      "Cbc0012I Integer solution of 148.2876 found by feasibility pump after 0 iterations and 0 nodes (0.01 seconds)\n",
      "Cbc0001I Search completed - best objective 148.2876002788544, took 0 iterations and 0 nodes (0.02 seconds)\n",
      "Cbc0035I Maximum depth 0, 0 variables fixed on reduced cost\n",
      "Cuts at root node changed objective from 148.288 to 148.288\n",
      "Probing was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "Gomory was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "Knapsack was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "Clique was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "MixedIntegerRounding2 was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "FlowCover was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "TwoMirCuts was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "\n",
      "Result - Optimal solution found\n",
      "\n",
      "Objective value:                148.28760028\n",
      "Enumerated nodes:               0\n",
      "Total iterations:               0\n",
      "Time (CPU seconds):             0.02\n",
      "Time (Wallclock seconds):       0.02\n",
      "\n",
      "Total time (CPU seconds):       0.02   (Wallclock seconds):       0.02\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Problem': [{'Name': 'unknown', 'Lower bound': 148.28760028, 'Upper bound': 148.28760028, 'Number of objectives': 1, 'Number of constraints': 387, 'Number of variables': 222, 'Number of binary variables': 65, 'Number of integer variables': 65, 'Number of nonzeros': 147, 'Sense': 'minimize'}], 'Solver': [{'Status': 'ok', 'User time': -1.0, 'System time': 0.02, 'Wallclock time': 0.02, 'Termination condition': 'optimal', 'Termination message': 'Model was solved to optimality (subject to tolerances), and an optimal solution is available.', 'Statistics': {'Branch and bound': {'Number of bounded subproblems': 0, 'Number of created subproblems': 0}, 'Black box': {'Number of iterations': 0}}, 'Error rc': 0, 'Time': 0.035745859146118164}], 'Solution': [OrderedDict([('number of solutions', 0), ('number of solutions displayed', 0)])]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gurobipy\n",
    "opt_model.obj = pe.Objective(expr=opt_model.gbt.outputs[0])\n",
    "solver = pe.SolverFactory('cbc')\n",
    "solver.solve(opt_model, tee=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "114c04fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs : Size=10, Index=gbt.inputs_set\n",
      "    Key : Lower : Value      : Upper : Fixed : Stale : Domain\n",
      "      0 : -5.12 :      -5.12 :  5.12 : False : False :  Reals\n",
      "      1 : -5.12 : -4.1146283 :  5.12 : False : False :  Reals\n",
      "      2 : -5.12 : -4.6973815 :  5.12 : False : False :  Reals\n",
      "      3 : -5.12 :      -5.12 :  5.12 : False : False :  Reals\n",
      "      4 : -5.12 :      -5.12 :  5.12 : False : False :  Reals\n",
      "      5 : -5.12 : -4.2737093 :  5.12 : False : False :  Reals\n",
      "      6 : -5.12 :      -5.12 :  5.12 : False : False :  Reals\n",
      "      7 : -5.12 :      -5.12 :  5.12 : False : False :  Reals\n",
      "      8 : -5.12 : -3.9166837 :  5.12 : False : False :  Reals\n",
      "      9 : -5.12 :      -5.12 :  5.12 : False : False :  Reals\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(opt_model.gbt.inputs.pprint())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748da606",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f512c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
